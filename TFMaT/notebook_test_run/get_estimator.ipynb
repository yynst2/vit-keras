{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c9643e-65f8-425a-aea2-b8756a668c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from vit_keras import vit, utils\n",
    "from TFMaT import *\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09dfa5e-ff28-4bbb-9dc7-b9b9b4002f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_TFMaT(\n",
    "    name='TFMat_test',\n",
    "    sequence_length=1000,\n",
    "    motif_size=6000,\n",
    "    num_layers=12,\n",
    "    num_heads=12,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    classes=1000,\n",
    "    representation_size=768,\n",
    "    motif_length_max=35,\n",
    "    include_top=True,\n",
    "    activation='sigmoid'\n",
    ")\n",
    "\n",
    "#\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# need compile\n",
    "model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0013c7ac-53cd-4f6a-ba19-90e28f38485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={}\n",
    "params['sequence_length']=1000\n",
    "params['motif_size']=6000\n",
    "params['motif_length_max']=35\n",
    "params['num_layers']=12 \n",
    "params['num_heads']=12\n",
    "params['name']='TFMaT_test'\n",
    "params['hidden_size']=768\n",
    "params['mlp_dim']=3072\n",
    "params['classes']=1000\n",
    "params['dropout']=0.1\n",
    "params['activation']='sigmoid'\n",
    "params['representation_size']=768\n",
    "params['motif_embedding_trainable']=False\n",
    "params[\"lr\"]=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53447ff8-6e10-4899-9372-b06d6568e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn\n",
    "def model_fn(features, labels, mode=tf.estimator.ModeKeys.TRAIN, params=None):\n",
    "    \n",
    "    # x = tf.keras.layers.Input(shape=(params['sequence_length'],4))\n",
    "    motif_embedding = tf.keras.layers.Conv1D(\n",
    "        filters=params['motif_size'],\n",
    "        kernel_size=params['motif_length_max'],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        name=\"motif_embedding\",\n",
    "    )\n",
    "    motif_embedding.trainable = params['motif_embedding_trainable']\n",
    "    y=motif_embedding(features)\n",
    "    y=tf.keras.layers.Dense(\n",
    "        units=params['hidden_size'],\n",
    "        name=\"motif_to_hidden_embedding\"\n",
    "    )(y)\n",
    "    y = layers.ClassToken(name=\"class_token\")(y)\n",
    "    y = layers.AddPositionEmbs(name=\"Transformer/posembed_input\")(y)\n",
    "    for n in range(params['num_layers']):\n",
    "        y, _ = layers.TransformerBlock(\n",
    "            num_heads=params['num_heads'],\n",
    "            mlp_dim=params['mlp_dim'],\n",
    "            dropout=params['dropout'],\n",
    "            name=f\"Transformer/encoderblock_{n}\",\n",
    "        )(y)\n",
    "    y = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6, name=\"Transformer/encoder_norm\"\n",
    "        )(y)\n",
    "    y = tf.keras.layers.Lambda(lambda v: v[:, 0],\n",
    "                               name=\"ExtractToken\")(y)\n",
    "\n",
    "    y = tf.keras.layers.Dense(\n",
    "        params['representation_size'],\n",
    "        name=\"pre_logits\",\n",
    "        activation=\"tanh\"\n",
    "    )(y)\n",
    "    \n",
    "    logits = tf.keras.layers.Dense(\n",
    "        params['classes'],\n",
    "        name=\"head\",\n",
    "        activation=params['activation'])(y) \n",
    "\n",
    "    learning_rate = tf.constant(params[\"lr\"])\n",
    "    loss_op = None\n",
    "    train_op = None\n",
    "    \n",
    "    if mode in (tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL):\n",
    "        loss_op = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "        )\n",
    "    train_op = tf.keras.optimizers.Adam(\n",
    "        learning_rate=learning_rate\n",
    "        ).minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    spec = CSEstimatorSpec (mode=mode, loss=loss_op, train_op=train_op)\n",
    "return spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f6f479d-7f92-434c-aa84-ca5d27effa44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TFMat_test\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1000, 4)]         0         \n",
      "                                                                 \n",
      " motif_embedding (Conv1D)    (None, 1000, 6000)        846000    \n",
      "                                                                 \n",
      " motif_to_hidden_embedding (  (None, 1000, 768)        4608768   \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " class_token (ClassToken)    (None, 1001, 768)         768       \n",
      "                                                                 \n",
      " Transformer/posembed_input   (None, 1001, 768)        768768    \n",
      " (AddPositionEmbs)                                               \n",
      "                                                                 \n",
      " Transformer/encoderblock_0   ((None, 1001, 768),      7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_1   ((None, 1001, 768),      7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_2   ((None, 1001, 768),      7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_3   ((None, 1001, 768),      7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_4   ((None, 1001, 768),      7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_5   ((None, 1001, 768),      7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_6   ((None, 1001, 768),      7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_7   ((None, 1001, 768),      7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_8   ((None, 1001, 768),      7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_9   ((None, 1001, 768),      7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_10  ((None, 1001, 768),      7087872   \n",
      "  (TransformerBlock)          (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_11  ((None, 1001, 768),      7087872   \n",
      "  (TransformerBlock)          (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoder_norm (L  (None, 1001, 768)        1536      \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " ExtractToken (Lambda)       (None, 768)               0         \n",
      "                                                                 \n",
      " pre_logits (Dense)          (None, 768)               590592    \n",
      "                                                                 \n",
      " head (Dense)                (None, 1000)              769000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,639,896\n",
      "Trainable params: 91,793,896\n",
      "Non-trainable params: 846,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7928efd3-f797-4378-8f38-a971465c0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_seq=np.random.random(size=(128,1000,4))\n",
    "dna_seq_exp=np.expand_dims(dna_seq,axis=-1)\n",
    "labels=np.random.randint(low=0,high=1000,size=(128,1))\n",
    "labels_cat=to_categorical(labels,num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb1e33e-3ac8-43fd-850c-fc0282dd4cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=model.predict(dna_seq,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "798842dd-e4b1-4e33-a4d0-e6f79941e5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21d452b2-57a1-4d86-8695-03a46a81db6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 34s 171ms/step - loss: 0.0276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26eec21f5f8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dna_seq,labels_cat,batch_size=1,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "072ac870-8950-4138-bdc0-c2a0c9769a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\YYNST\\AppData\\Local\\Temp\\tmpmlkmeajy\n",
      "INFO:tensorflow:Using the Keras model provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YYNST\\AppData\\Local\\conda\\conda\\envs\\gpu_py37\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\YYNST\\\\AppData\\\\Local\\\\Temp\\\\tmpmlkmeajy', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "params={}\n",
    "params['batch_size']=64\n",
    "est = tf.keras.estimator.model_to_estimator(keras_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8137de8a-c7e5-4f20-a29e-dded50292265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate potential training data size \n",
    "dna_seq=np.random.random(size=(128,1,1000,4))\n",
    "\n",
    "dna_seq.size * dna_seq.itemsize/1024/1024 \n",
    "\n",
    "3.90625* 3101788170/1000 *0.1 /1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc4aa052-1311-45d3-a951-407b28318a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cat=np.expand_dims(labels_cat,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55902b8c-c63c-4424-a13f-51b46622b5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1, 1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef00f5df-bfcc-41b4-90f5-281bf95a3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    batch_size = 64\n",
    "    dna_seq=np.random.random(size=(128,1,1000,4))\n",
    "    dna_seq_exp=np.expand_dims(dna_seq,axis=-1)\n",
    "    labels=np.random.randint(low=0,high=1000,size=(128,1))\n",
    "    labels_cat=to_categorical(labels,num_classes=1000)\n",
    "    labels_cat=np.expand_dims(labels_cat,1)\n",
    "    \n",
    "    dataset=Dataset.from_tensor_slices((dna_seq,labels_cat))\n",
    "    dataset.shuffle(128, reshuffle_each_iteration=True).batch(batch_size,drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11666702-d2ba-4021-bec3-974ec69dc3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\YYNST\\\\AppData\\\\Local\\\\Temp\\\\tmpmlkmeajy\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: C:\\Users\\YYNST\\AppData\\Local\\Temp\\tmpmlkmeajy\\keras\\keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 204 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\YYNST\\AppData\\Local\\Temp\\tmpmlkmeajy\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.009471378, step = 0\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10...\n",
      "INFO:tensorflow:Saving checkpoints for 10 into C:\\Users\\YYNST\\AppData\\Local\\Temp\\tmpmlkmeajy\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10...\n",
      "INFO:tensorflow:Loss for final step: 0.009296461.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x26f13217438>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.train(\n",
    "input_fn=input_fn,\n",
    "max_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5507d04-3bf6-46e2-99eb-0d37eb3270cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x26f13217438>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esttrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4f847-e984-4aac-bb42-ee1f246fd31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFtrainexample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff5ca0-3780-4706-9c32-543ce5aba922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn\n",
    "def model_fn(features, labels, mode=tf.estimator.ModeKeys.TRAIN, params=None): \n",
    "    net = tf.keras.layers.Dense(256, activation=tf.nn.relu)(features)\n",
    "    net = tf.keras.layers.Dense(128, activation=tf.nn.relu)(net)\n",
    "    logits = tf.keras.layers.Dense(params[\"num_classes\"])(net)\n",
    "    learning_rate = tf.constant(params[\"lr\"])\n",
    "    loss_op = None\n",
    "    train_op = None\n",
    "    if mode in (tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL):\n",
    "        loss_op = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits)\n",
    "        )\n",
    "    train_op = tf.train.GradientDescentOptimizer(\n",
    "        learning_rate=learning_rate\n",
    "        ).minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    spec = CSEstimatorSpec (mode=mode, loss=loss_op, train_op=train_op)\n",
    "return spec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a740ce-5284-41b0-aa57-118d609b5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.EstimatorSpec(\n",
    "    mode, predictions=None, loss=None, train_op=None, eval_metric_ops=None,\n",
    "    export_outputs=None, training_chief_hooks=None, training_hooks=None,\n",
    "    scaffold=None, evaluation_hooks=None, prediction_hooks=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b764506d-2461-4005-9cf4-6fab8f505a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator\n",
    "est = tf.estimator.Estimator(model_dir=model_dir,\n",
    "                                    model_fn=model_fn,\n",
    "                                    params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b5fbf-848f-4ca1-900f-fc1c1b44b362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad86e9-8b83-4eb0-a6c9-88f0486abb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerebras example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d3dd1-4b7d-4443-9d72-dc106d297562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn\n",
    "def model_fn(features, labels, mode=tf.estimator.ModeKeys.TRAIN, params=None):\n",
    "    net = tf.keras.layers.Dense(256, activation=tf.nn.relu)(features)\n",
    "    net = tf.keras.layers.Dense(128, activation=tf.nn.relu)(net)\n",
    "    logits = tf.keras.layers.Dense(params[\"num_classes\"])(net)\n",
    "    learning_rate = tf.constant(params[\"lr\"])\n",
    "    loss_op = None\n",
    "    train_op = None\n",
    "    if mode in (tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL):\n",
    "        loss_op = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits)\n",
    "        )\n",
    "    train_op = tf.train.GradientDescentOptimizer(\n",
    "        learning_rate=learning_rate\n",
    "        ).minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    spec = CSEstimatorSpec (mode=mode, loss=loss_op, train_op=train_op)\n",
    "return spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89195de2-4280-4817-ad6a-d0f640d47424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fn\n",
    "def train_input_fn(params):\n",
    "    batch_size = params[\"batch_size\"]\n",
    "    iris_dtype = np.dtype([('img', \"float32\", 4),\n",
    "    ('lbl', \"int32\", ``)])\n",
    "    data = np.genfromtxt(\n",
    "    \"./data/iris_training.csv\",\n",
    "    dtype=iris_dtype,\n",
    "    delimiter=\",\"\n",
    "    )\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (data[\"img\"][:], data[\"lbl\"][:])\n",
    "    )\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size,\n",
    "    drop_remainder=True)\n",
    "return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31421198-fc7b-41af-8f71-f0f350783e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "from common_zoo.estimator.tf.run_config import CSRunConfig\n",
    "\n",
    "config = CSRunConfig(\n",
    "    cs_ip=ip,\n",
    "    save_checkpoints_steps=1000,\n",
    "    log_step_count_steps=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406bc368-3d85-4bae-8ffe-1eb9f86441ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator\n",
    "est = CerebrasEstimator(\n",
    "    model_fn=model_fn,\n",
    "    config=config,\n",
    "    params=params,\n",
    "    model_dir='./out',\n",
    ")\n",
    "\n",
    "# train\n",
    "est.train(input_fn=input_fn, steps=100000, use_cs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
